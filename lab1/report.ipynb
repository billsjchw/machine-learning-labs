{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 手机定价分类\n",
    "\n",
    "## 概述\n",
    "\n",
    "本文处理的学习任务是根据一台手机的各类属性(如电池容量, 是否支持蓝牙等等)推断该手机的定价类别(低定价或高定价).\n",
    "本文采用的数据集为[dataset](https://www.kaggle.com/iabhishekofficial/mobile-price-classification?select=train.csv).\n",
    "原始数据集将定价分为四类: \"低\", \"中\", \"高\"与\"非常高\", 本文将\"低\"与\"中\"合并为低定价, 将\"高\"与\"非常高\"合并为高定价.\n",
    "本文处理的是一个二分类任务, 正类为高定价, 用$1$表示, 反类为低定价, 用$0$表示.\n",
    "\n",
    "数据集以8:1:1的比例被切分为训练集, 验证集和测试集. 本文以逻辑回归, 朴素贝叶斯分类器和支持向量机三种学习算法处理学习任务,\n",
    "并对比了这三种方法在测试集上的预测准确率, 在训练集上的预测准确率和训练用时. 本文还分析了这三种学习算法的差异与优缺点.\n",
    "\n",
    "## 导入所需的包与类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas\n",
    "import functools\n",
    "import time\n",
    "import seaborn\n",
    "from matplotlib import pyplot\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 工具函数\n",
    "### 数据集切分\n",
    "函数`split(data, train, valid, test)`按照`train`:`valid`:`test`的比例将表格`data`横向切分为三份,\n",
    "并返回这三份表格."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def split(data, train, valid, test):\n",
    "    # calculate the size of each part\n",
    "    size = len(data)\n",
    "    size_train = int(size * train / (train + valid + test))\n",
    "    size_valid = int(size * valid / (train + valid + test))\n",
    "\n",
    "    # split the data\n",
    "    data_train = data[0:size_train].copy()\n",
    "    data_valid = data[size_train:size_train + size_valid].copy()\n",
    "    data_test = data[size_train + size_valid:size].copy()\n",
    "\n",
    "    return data_train, data_valid, data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 分离属性与标记\n",
    "函数`get_xs_ys(data)`将表格`data`中标记一列(price_range)与其他列分离开来,\n",
    "并返回分离后的两部分."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_xs_ys(data):\n",
    "    xs = data.drop('price_range', axis=1).values.tolist()\n",
    "    ys = data['price_range'].values.tolist()\n",
    "    return xs, ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 计算预测准确率\n",
    "函数`score(model, xs, ys)`用模型`model`对一组样本`xs`进行预测,\n",
    "并将预测结果与相应的一组参考标记`ys`进行比对, 计算出预测准确率."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def score(model, xs, ys):\n",
    "    # conduct the prediction\n",
    "    predicted_ys = model.predict(xs)\n",
    "\n",
    "    # calculate the error rate\n",
    "    return sum([y == predicted_y for y, predicted_y in zip(ys, predicted_ys)]) / len(xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 驱动函数\n",
    "函数`run(preprocessor, model_class, data)`依次执行预处理, 数据集切分, 模型训练与预测准确率评估,\n",
    "然后返回测试集上的预测准确率, 训练集上的预测准确率与模型训练所用时间(单位: 秒).\n",
    "所用预处理函数由参数`preprocessor`指定, 所用学习算法由参数`model_class`指定,\n",
    "所用数据由参数`data`指定."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run(preprocessor, model_class, data):\n",
    "    # preprocess\n",
    "    data = preprocessor(data)\n",
    "\n",
    "    # split the data into training set, validation set and test set\n",
    "    data_train, data_valid, data_test = split(data, 8, 1, 1)\n",
    "\n",
    "    # split attributes and label\n",
    "    xs_train, ys_train = get_xs_ys(data_train)\n",
    "    xs_valid, ys_valid = get_xs_ys(data_valid)\n",
    "    xs_test, ys_test = get_xs_ys(data_test)\n",
    "\n",
    "    # train a model\n",
    "    model = model_class()\n",
    "    time_start = time.time()\n",
    "    model.fit(xs_train, ys_train)\n",
    "    time_finish = time.time()\n",
    "\n",
    "    # calculate the error rates and the time used to train the model\n",
    "    score_test = score(model, xs_test, ys_test)\n",
    "    score_train = score(model, xs_train, ys_train)\n",
    "    time_cost = time_finish - time_start\n",
    "\n",
    "    return score_test, score_train, time_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 预处理函数与模型类\n",
    "\n",
    "对于每个学习算法, 都有一个预处理函数与一个模型类.\n",
    "\n",
    "预处理函数`preprocess(data)`对表格`data`中的原始数据进行预处理,\n",
    "然后返回处理后的数据表格.\n",
    "\n",
    "模型类有两个成员方法. 第一个成员方法是`fit(self, xs, ys)`,\n",
    "它会使用一组样本`xs`与对应的一组标记`ys`来训练模型, 并将训练得到的模型存放在`self`对象中.\n",
    "第二个成员方法是`predict(self, xs)`, 它会使用`self`对象中的模型来对一组样本`xs`进行预测,\n",
    "然后返回预测结果(一组标记).\n",
    "\n",
    "### 逻辑回归\n",
    "\n",
    "逻辑回归的预处理函数为`preprocess_logistic`. 在预处理过程中,\n",
    "原始数据中每个属性值都调整到$[0, 1]$区间中, 这样做可以避免模型训练过程中出现数据溢出的问题."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_logistic(data):\n",
    "    # avoid to change the original DataFrame object\n",
    "    data = data.copy()\n",
    "\n",
    "    # normalize data\n",
    "    for col_name in data.columns:\n",
    "        if col_name != 'price_range':\n",
    "            s = data[col_name].max()\n",
    "            data[col_name] = data[col_name].apply(lambda x: x / s)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "逻辑回归的模型类为`LogisticRegression`. 成员变量`ws`表示模型对应的$logit$函数的参数向量$(w_0, w_1, \\ldots, w_d)$.\n",
    "私有成员方法`_calc_post_prob(self, x)`使用`self`对象中的模型计算样本`x`属于正类的后验概率."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self):\n",
    "        self.ws = []\n",
    "\n",
    "    def fit(self, xs, ys):\n",
    "        # define constants\n",
    "        eta = 0.005\n",
    "        conv_bound = 0.01 # convergence bound\n",
    "\n",
    "        # calculate number of attributes\n",
    "        attr_num = len(xs[0]) + 1\n",
    "\n",
    "        # initialize params of logit function\n",
    "        self.ws = [0.0] * attr_num\n",
    "\n",
    "        # learn the params with gradient-descent algorithm\n",
    "        while True:\n",
    "            dws = [0.0] * attr_num\n",
    "            for x, y in zip(xs, ys):\n",
    "                post_prob = self._calc_post_prob(x)\n",
    "                dws = [dw + (y - post_prob) * attr for dw, attr in zip(dws, [1.0, *x])]\n",
    "            if all([abs(eta * dw) < conv_bound for dw in dws]):\n",
    "                break\n",
    "            self.ws = [w + eta * dw for w, dw in zip(self.ws, dws)]\n",
    "\n",
    "    def predict(self, xs):\n",
    "        return [int(self._calc_post_prob(x) > 0.5) for x in xs]\n",
    "\n",
    "    def _calc_post_prob(self, x):\n",
    "        a = sum([w * attr for w, attr in zip(self.ws, [1.0, *x])])\n",
    "        return 1 / (1 + math.exp(-a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 朴素贝叶斯分类器\n",
    "\n",
    "朴素贝叶斯分类器的预处理函数为`preprocess_bayesian`. 原始数据中,\n",
    "有一些属性有很多可能的取值, 使得模型在预测时难以用训练数据估计这些属性上的似然.\n",
    "在预处理过程中, 对于这些属性, 属性取值范围被划分为一组区间, 每个属性值被其所属的区间的编号所替代."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_bayesian(data):\n",
    "    # avoid to change the original DataFrame object\n",
    "    data = data.copy()\n",
    "\n",
    "    # discretize continuous attributes into intervals\n",
    "    # split large numbers into ranges\n",
    "    data['battery_power'] = pandas.cut(data['battery_power'], 10, labels=False)\n",
    "    data['clock_speed'] = pandas.cut(data['clock_speed'], 10, labels=False)\n",
    "    data['int_memory'] = pandas.cut(data['int_memory'], 10, labels=False)\n",
    "    data['mobile_wt'] = pandas.cut(data['mobile_wt'], 10, labels=False)\n",
    "    data['px_height'] = pandas.cut(data['px_height'], 10, labels=False)\n",
    "    data['px_width'] = pandas.cut(data['px_width'], 10, labels=False)\n",
    "    data['ram'] = pandas.cut(data['ram'], 10, labels=False)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "朴素贝叶斯分类器的模型类为`NaiveBayesianClassifier`.\n",
    "成员变量`tables`的意义: `tables[c][i][x]`记录了训练数据中属于第`c`类且第`i`个属性取值为`x`的样例个数.\n",
    "成员变量`ns`记录了训练数据中正类与反类的样例个数. 模型的训练过程即为统计得到这两个成员变量的过程."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class NaiveBayesianClassifier:\n",
    "    def __init__(self):\n",
    "        self.tables = [[], []]\n",
    "        self.ns = [0, 0]\n",
    "\n",
    "    def fit(self, xs, ys):\n",
    "        # calculate number of attributes\n",
    "        attr_num = len(xs[0])\n",
    "\n",
    "        # count\n",
    "        for c in [0, 1]:\n",
    "            self.ns[c] = ys.count(c)\n",
    "            self.tables[c] = [dict() for _ in range(attr_num)]\n",
    "            for x in [x for x, y in zip(xs, ys) if y == c]:\n",
    "                for attr, row in zip(x, self.tables[c]):\n",
    "                    row.setdefault(attr, 0)\n",
    "                    row[attr] += 1\n",
    "\n",
    "    def predict(self, xs):\n",
    "        # calculate number of attributes\n",
    "        attr_num = len(xs[0])\n",
    "\n",
    "        # calculate the prior probabilities\n",
    "        total = sum(self.ns)\n",
    "        prior_probs = [self.ns[c] / total for c in [0, 1]]\n",
    "\n",
    "        # conduct the prediction\n",
    "        ys = []\n",
    "        for x in xs:\n",
    "            f = [0.0, 0.0]\n",
    "            for c in [0, 1]:\n",
    "                # calculate the likelihood of each attribute\n",
    "                likelihoods = [self.tables[c][i].get(x[i], 0) / self.ns[c] for i in range(attr_num)]\n",
    "                # calculate the decision function value\n",
    "                f[c] = functools.reduce(lambda v, e: v * e, [prior_probs[c], *likelihoods])\n",
    "            # take the class with the max decision function value\n",
    "            ys.append(f.index(max(f)))\n",
    "\n",
    "        return ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 支持向量机\n",
    "\n",
    "支持向量机的预处理函数为`preprocess_svm`. 预处理过程没有对原始数据做修改."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_svm(data):\n",
    "    # avoid to change the original DataFrame object\n",
    "    data = data.copy()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "支持向量机的模型类为`SVM`. 该类的实现借助了`sklearn.svm.SVC`类."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self):\n",
    "        self.svc = SVC()\n",
    "\n",
    "    def fit(self, xs, ys):\n",
    "        self.svc.fit(xs, ys)\n",
    "\n",
    "    def predict(self, xs):\n",
    "        return self.svc.predict(xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 学习算法对比\n",
    "\n",
    "函数`compare(n)`将原始数据打乱`n`次, 产生`n`种不同的数据集切分,\n",
    "对于每一种数据集切分, 测试三种学习算法在测试集上的预测准确率, 在训练集上的预测准确率与训练用时.\n",
    "该函数会以表格形式输出平均预测准确率与平均训练用时, 还会以柱状图的形式对比不同学习算法的平均预测准确率."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compare(n):\n",
    "    # define the name of each method\n",
    "    names = ['logistic', 'bayesian', 'svm']\n",
    "\n",
    "    # define the preprocessor and the model class of each method\n",
    "    preprocessors = {\n",
    "        'logistic': preprocess_logistic,\n",
    "        'bayesian': preprocess_bayesian,\n",
    "        'svm': preprocess_svm\n",
    "    }\n",
    "    model_classes = {\n",
    "        'logistic': LogisticRegression,\n",
    "        'bayesian': NaiveBayesianClassifier,\n",
    "        'svm': SVM\n",
    "    }\n",
    "\n",
    "    # initialize the statistics\n",
    "    avg_scores_test = {'logistic': 0.0, 'bayesian': 0.0, 'svm': 0.0}\n",
    "    avg_scores_train = {'logistic': 0.0, 'bayesian': 0.0, 'svm': 0.0}\n",
    "    avg_elapsed_times = {'logistic': 0.0, 'bayesian': 0.0, 'svm': 0.0}\n",
    "\n",
    "    # read the data\n",
    "    data = pandas.read_csv('train.csv')\n",
    "\n",
    "    # convert labels into two classes\n",
    "    data['price_range'].replace([1, 2, 3, 4], [0, 0, 1, 1], True)\n",
    "\n",
    "    # repeat the experiment n times\n",
    "    for _ in range(n):\n",
    "        # shuffle the data\n",
    "        data = data.sample(frac=1)\n",
    "        # run the experiment for each method\n",
    "        for name in names:\n",
    "            score_test, score_train, elapsed_time = run(preprocessors[name], model_classes[name], data)\n",
    "            avg_scores_test[name] += score_test / n\n",
    "            avg_scores_train[name] += score_train / n\n",
    "            avg_elapsed_times[name] += elapsed_time / n\n",
    "\n",
    "    # print the statistics\n",
    "    print('Method    Accuracy (Test)  Accuracy (Training)  Time (sec)')\n",
    "    fmt_str = '{:<8}  {:>15.2%}  {:>19.2%}  {:>10.3f}'\n",
    "    for name in names:\n",
    "        print(fmt_str.format(name, avg_scores_test[name], avg_scores_train[name], avg_elapsed_times[name]))\n",
    "\n",
    "    # show the result of accuracy comparison with a bar chart\n",
    "    pyplot.figure()\n",
    "    seaborn.barplot(\n",
    "        names * 2,\n",
    "        [avg_scores_test[name] for name in names] + [avg_scores_train[name] for name in names],\n",
    "        ['Test'] * 3 + ['Training'] * 3\n",
    "    )\n",
    "    pyplot.xlabel('Method')\n",
    "    pyplot.ylabel('Accuracy')\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "运行一次`compare`函数(运行时间可能较长)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method    Accuracy (Test)  Accuracy (Training)  Time (sec)\n",
      "logistic           98.40%               99.05%       7.968\n",
      "bayesian           93.00%               95.06%       0.012\n",
      "svm                97.20%               98.15%       0.019\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "从表格中可以看出, 逻辑回归的训练用时较长, 而朴素贝叶斯分类器与支持向量机的训练用时较短.\n",
    "朴素贝叶斯分类器的训练过程是一个简单的计数过程, 所以训练很高效. 逻辑回归与支持向量机的训练都用到了迭代优化的方法,\n",
    "两者训练时间上的差异主要是由于具体实现的性能优化程度不同所致的.\n",
    "\n",
    "从表格和柱状图中可以看出, 三个学习算法在训练集和测试集上都取得了不错的预测准确率,\n",
    "逻辑回归和支持向量机的预测准确率相当, 而朴素贝叶斯分类器的预测准确率略低于另两者.\n",
    "朴素贝叶斯分类器假设属性两两之间条件独立, 而现实数据并不完全符合这一假设,\n",
    "所以朴素贝叶斯分类器的预测准确率略低于另两个学习算法.\n",
    "\n",
    "三个学习算法的不同体现在它们从不同角度进行建模. 逻辑回归对后验概率进行建模,\n",
    "提出了$logit(P(C_1 \\mid \\boldsymbol{x})) = \\boldsymbol{w}^\\mathrm{T}\\boldsymbol{x} + w_0$.\n",
    "朴素贝叶斯学习器对属性与标记的联合概率建模, 提出了$P(x_1, x_2, \\ldots, x_d, c) = P(c)\\prod_{i=1}^dP(x_i \\mid c)$.\n",
    "支持向量机从几何的角度建模, 试图找出一个最优的超平面来划分两类数据点.\n",
    "\n",
    "三个学习算法的优缺点主要体现在以下几个方面.\n",
    "\n",
    "1. 多分类: 朴素贝叶斯分类器与逻辑回归都可以直接应用于多分类任务. 支持向量机应用于多分类任务则较为困难.\n",
    "\n",
    "2. 性能: 朴素贝叶斯分类器的训练过程是一个简单的计数过程, 用时较短.\n",
    "逻辑回归与支持向量机的训练都用到了迭代优化的方法, 用时较长.\n",
    "\n",
    "3. 假设: 逻辑回归假设每个属性都服从正态分布, 支持向量机假设在应用核方法之后两类数据点是线性可分的,\n",
    "这两个假设在现实任务中被满足的可能性较高. 朴素贝叶斯分类器假设属性两两之间条件独立,\n",
    "这个假设在现实任务中被满足的可能性较低.\n",
    "\n",
    "4. 预处理: 逻辑回归与支持向量机的预处理过程需要将非数值型的属性的每个属性值映射为一个数值.\n",
    "朴素贝叶斯分类器的预处理过程需要将非离散属性离散化."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}